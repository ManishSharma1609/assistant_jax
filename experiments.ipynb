{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Building from source — JAX  documentation\n",
      "Content snippet: Building from source — JAX documentation Skip to main content .md Building from source Contents Building from source # First, obtain the JAX source code: \n",
      "```python\n",
      "git clone https://github.com/jax-ml/jax\n",
      "cd jax\n",
      "```\n",
      " Building JAX involves two steps: Building or installing jaxlib , the C++ support library for jax . Installing the jax Python package. Building or installing jaxlib # Installing jaxlib with pip # If you’re only modifying Python portions of JAX, we recommend installing jaxlib from a prebuilt wheel using pip: pip install jaxlib See the JAX readme for full guidance on pip installation (e.g., for GPU and TPU support). Building jaxlib from source # Warning While it should typically be possible to compile jaxlib from source using most modern compilers, the builds are only tested using clang. Pull requests are welcomed to improve support for different toolchains, but other compilers are not actively supported. To build jaxlib from source, you must also install some prerequisites: A C++ compiler: As mentioned in the box above, it is best to use a recent version of clang (at the time of writing, the version we test is 18), but other compilers (e.g. g++ or MSVC) may work. On Ubuntu or Debian you can follow the instructions from the LLVM documentation to install the latest stable version of clang. If you are building on a Mac, make sure XCode and the XCode command line tools are installed. See below for Windows build instructions. Python: for running the build helper script. Note that there is no need to install Python dependencies locally, as your system Python will be ignored during the build; please check Managing hermetic Python for details. To build jaxlib for CPU or TPU, you can run: \n",
      "```python\n",
      "python build/build.py build --wheels=jaxlib --verbose\n",
      "pip install dist/*.whl  # installs jaxlib (includes XLA)\n",
      "```\n",
      " To build a wheel for a version of Python different from your current system installation pass --python_version flag to the build command: \n",
      "```python\n",
      "python build/build.py build --wheels=jaxlib --python_version=3.12 --verbose\n",
      "```\n",
      " The rest of this document assumes that you are building for Python version matching your current system installation. If you need to build for a different version, simply append --python_version=<py version> flag every time you call python build/build.py . Note, the Bazel build will always use a hermetic Python installation regardless of whether the --python_version parameter is passed or not. If you would like to build jaxlib and the CUDA plugins: Run \n",
      "```python\n",
      "python build/build.py build --wheels=jaxlib,jax-cuda-plugin,jax-cuda-pjrt\n",
      "```\n",
      " to generate three wheels (jaxlib without cuda, jax-cuda-plugin, and jax-cuda-pjrt). By default all CUDA compilation steps performed by NVCC and clang, but it can be restricted to clang via the --build_cuda_with_clang flag. See python build/build.py --help for configuration options. Here python should be the name of your Python 3 interpreter; on some systems, you may need to use python3 instead. Despite calling the script with python , Bazel will always use its own hermetic Python interpreter and dependencies, only the build/build.py script itself will be processed by your system Python interpreter. By default, the wheel is written to the dist/ subdirectory of the current directory. JAX versions starting from v.0.4.32: you can provide custom CUDA and CUDNN versions in the configuration options. Bazel will download them and use as target dependencies. To download the specific versions of CUDA/CUDNN redistributions, you can use the --cuda_version and --cudnn_version flags: \n",
      "```python\n",
      "python build/build.py build --wheels=jax-cuda-plugin --cuda_version=12.3.2 \\\n",
      "--cudnn_version=9.1.1\n",
      "```\n",
      " or \n",
      "```python\n",
      "python build/build.py build --wheels=jax-cuda-pjrt --cuda_version=12.3.2 \\\n",
      "--cudnn_version=9.1.1\n",
      "```\n",
      " Please note that these parameters are optional: by default Bazel will download CUDA and CUDNN redistribution versions provided in .bazelrc in the environment variables HERMETIC_CUDA_VERSION and HERMETIC_CUDNN_VERSION respectively. To point to CUDA/CUDNN/NCCL redistributions on local file system, you can use the following command: \n",
      "```python\n",
      "python build/build.py build --wheels=jax-cuda-plugin \\\n",
      "--bazel_options=--repo_env=LOCAL_CUDA_PATH=\"/foo/bar/nvidia/cuda\" \\\n",
      "--bazel_options=--repo_env=LOCAL_CUDNN_PATH=\"/foo/bar/nvidia/cudnn\" \\\n",
      "--bazel_options=--repo_env=LOCAL_NCCL_PATH=\"/foo/bar/nvidia/nccl\"\n",
      "```\n",
      " Please see the full list of instructions in XLA documentation . JAX versions prior v.0.4.32: you must have CUDA and CUDNN installed and provide paths to them using configuration options. Building jaxlib from source with a modified XLA repository. # JAX depends on XLA, whose source code is in the XLA GitHub repository . By default JAX uses a pinned copy of the XLA repository, but we often want to use a locally-modified copy of XLA when working on JAX. There are two ways to do this: use Bazel’s override_repository feature, which you can pass as a command line flag to build.py as follows: \n",
      "```python\n",
      "python build/build.py build --wheels=jaxlib --local_xla_path=/path/to/xla\n",
      "```\n",
      " modify the WORKSPACE file in the root of the JAX source tree to point to a different XLA tree. To contribute changes back to XLA, send PRs to the XLA repository. The version of XLA pinned by JAX is regularly updated, but is updated in particular before each jaxlib release. Additional Notes for Building jaxlib from source on Windows # Note: JAX does not support CUDA on Windows; use WSL2 for CUDA support. On Windows, follow Install Visual Studio to set up a C++ toolchain. Visual Studio 2019 version 16.5 or newer is required. JAX builds use symbolic links, which require that you activate Developer Mode . You can either install Python using its Windows installer , or if you prefer, you can use Anaconda or Miniconda to set up a Python environment. Some targets of Bazel use bash utilities to do scripting, so MSYS2 is needed. See Installing Bazel on Windows for more details. Install the following packages: pacman - S patch coreutils Once coreutils is installed, the realpath command should be present in your shell’s path. Once everything is installed. Open PowerShell, and make sure MSYS2 is in the path of the current session. Ensure bazel , patch and realpath are accessible. Activate the conda environment. python . \\ build \\ build . py build -- wheels = jaxlib To build with debug information, add the flag --bazel_options='--copt=/Z7' . Additional notes for building a ROCM jaxlib for AMD GPUs # For detailed instructions on building jaxlib with ROCm support, refer to the official guide: Build ROCm JAX from Source Managing hermetic Python # To make sure that JAX’s build is reproducible, behaves uniformly across supported platforms (Linux, Windows, MacOS) and is properly isolated from specifics of a local system, we rely on hermetic Python (provided by rules_python , see Toolchain Registration for details) for all build and test commands executed via Bazel. This means that your system Python installation will be ignored during the build and Python interpreter itself as well as all the Python dependencies will be managed by bazel directly. Specifying Python version # When you run build/build.py tool, the version of hermetic Python is set automatically to match the version of the Python you used to run build/build.py script. To choose a specific version explicitly you may pass --python_version argument to the tool: python build / build . py build -- python_version = 3.12 Under the hood, the hermetic Python version is controlled by HERMETIC_PYTHON_VERSION environment variable, which is set automatically when you run build/build.py . In case you run bazel directly you may need to set the variable explicitly in one of the following ways: \n",
      "```python\n",
      "# Either add an entry to your `.bazelrc` file\n",
      "build --repo_env=HERMETIC_PYTHON_VERSION=3.12\n",
      "\n",
      "# OR pass it directly to your specific build command\n",
      "bazel build <target> --repo_env=HERMETIC_PYTHON_VERSION=3.12\n",
      "\n",
      "# OR set the environment variable globally in your shell:\n",
      "export HERMETIC_PYTHON_VERSION=3.12\n",
      "```\n",
      " You may run builds and tests against different versions of Python sequentially on the same machine by simply switching the value of --python_version between the runs. All the python-agnostic parts of the build cache from the previous build will be preserved and reused for the subsequent builds. Specifying Python dependencies # During bazel build all JAX’s Python dependencies are pinned to their specific versions. This is necessary to ensure reproducibility of the build. The pinned versions of the full transitive closure of JAX’s dependencies together with their corresponding hashes are specified in build/requirements_lock_<python version>.txt files ( e.g. build/requirements_lock_3_12.txt for Python 3.12 ). To update the lock files, make sure build/requirements.in contains the desired direct dependencies list and then execute the following command (which will call pip-compile under the hood): \n",
      "```python\n",
      "python build/build.py requirements_update --python_version=3.12\n",
      "```\n",
      " Alternatively, if you need more control, you may run the bazel command directly (the two commands are equivalent): \n",
      "```python\n",
      "bazel run //build:requirements.update --repo_env=HERMETIC_PYTHON_VERSION=3.12\n",
      "```\n",
      " where 3.12 is the Python version you wish to update. Note, since it is still pip and pip-compile tools used under the hood, so most of the command line arguments and features supported by those tools will be acknowledged by the Bazel requirements updater command as well. For example, if you wish the updater to consider pre-release versions simply pass --pre argument to the bazel command: \n",
      "```python\n",
      "bazel run //build:requirements.update --repo_env=HERMETIC_PYTHON_VERSION=3.12 -- --pre\n",
      "```\n",
      " Specifying dependencies on local wheels # By default the build scans dist directory in the repository root for any local .whl files to be included in the list of dependencies. If the wheel is Python version specific, only the wheels that match the selected Python version will be included. The overall local wheel search and selection logic is controlled by the arguments to python_init_repositories() macro (called directly from the WORKSPACE file). You may use local_wheel_dist_folder to change the location of the folder with local wheels. Use local_wheel_inclusion_list and local_wheel_exclusion_list arguments to specify which wheels should be included and/or excluded from the search (it supports basic wildcard matching). If necessary, you can also depend on a local .whl file manually, bypassing the automatic local wheel search mechanism. For example to depend on your newly built jaxlib wheel, you may add a path to the wheel in build/requirements.in and re-run the requirements updater command for a selected version of Python. For example: \n",
      "```python\n",
      "echo -e \"\\n$(realpath jaxlib-0.4.27.dev20240416-cp312-cp312-manylinux2014_x86_64.whl)\" >> build/requirements.in\n",
      "python build/build.py requirements_update --python_version=3.12\n",
      "```\n",
      " Specifying dependencies on nightly wheels # To build and test against the very latest, potentially unstable, set of Python dependencies we provide a special version of the dependency updater command as follows: \n",
      "```python\n",
      "python build/build.py requirements_update --python_version=3.12 --nightly_update\n",
      "```\n",
      " Or, if you run bazel directly (the two commands are equivalent): \n",
      "```python\n",
      "bazel run //build:requirements_nightly.update --repo_env=HERMETIC_PYTHON_VERSION=3.12\n",
      "```\n",
      " The difference between this and the regular updater is that by default it would accept pre-release, dev and nightly packages, it will also search https://pypi.anaconda.org/scientific-python-nightly-wheels/simple as an extra index url and will not put hashes in the resultant requirements lock file. Customizing hermetic Python (Advanced Usage) # We support all of the current versions of Python out of the box, so unless your workflow has very special requirements (such as ability to use your own custom Python interpreter) you may safely skip this section entirely. In short, if you rely on a non-standard Python workflow you still can achieve the great level of flexibility in hermetic Python setup. Conceptually there will be only one difference compared to non-hermetic case: you will need to think in terms of files, not installations (i.e. think what files your build actually depends on, not what files need to be installed on your system), the rest is pretty much the same. So, in practice, to gain full control over your Python environment, hermetic or not you need to be able to do the following three things: Specify which python interpreter to use (i.e. pick actual python or python3 binary and libs that come with it in the same folder). Specify a list of Python dependencies (e.g. numpy ) and their actual versions. Be able to add/remove/update dependencies in the list easily. Each dependency itself could be custom too (self-built for example). You already know how to do all of the steps above in a non-hermetic Python environment, here is how you do the same in the hermetic one (by approaching it in terms of files, not installations): Instead of installing Python, get Python interpreter in a tar or zip file. Depending on your case you may simply pull one of many existing ones (such as python-build-standalone ), or build your own and pack it in an archive (following official build instructions will do just fine). E.g. on Linux it will look something like the following: \n",
      "```python\n",
      "./configure --prefix python\n",
      "make -j12\n",
      "make altinstall\n",
      "tar -czpf my_python.tgz python\n",
      "```\n",
      " Once you have the tarball ready, plug it in the build by pointing HERMETIC_PYTHON_URL env var to the archive (either local one or from the internet): \n",
      "```python\n",
      "--repo_env=HERMETIC_PYTHON_URL=\"file:///local/path/to/my_python.tgz\"\n",
      "--repo_env=HERMETIC_PYTHON_SHA256=<file's_sha256_sum>\n",
      "\n",
      "# OR\n",
      "--repo_env=HERMETIC_PYTHON_URL=\"https://remote/url/to/my_python.tgz\"\n",
      "--repo_env=HERMETIC_PYTHON_SHA256=<file's_sha256_sum>\n",
      "\n",
      "# We assume that top-level folder in the tarbal is called \"python\", if it is\n",
      "# something different just pass additional HERMETIC_PYTHON_PREFIX parameter\n",
      "--repo_env=HERMETIC_PYTHON_URL=\"https://remote/url/to/my_python.tgz\"\n",
      "--repo_env=HERMETIC_PYTHON_SHA256=<file's_sha256_sum>\n",
      "--repo_env=HERMETIC_PYTHON_PREFIX=\"my_python/install\"\n",
      "```\n",
      " Instead of doing pip install create requirements_lock.txt file with full transitive closure of your dependencies. You may also depend on the existing ones already checked in this repo (as long as they work with your custom Python version). There are no special instructions on how you do it, you may follow steps recommended in Specifying Python dependencies from this doc, just call pip-compile directly (note, the lock file must be hermetic, but you can always generate it from non-hermetic python if you’d like) or even create it manually (note, hashes are optional in lock files). If you need to update or customize your dependencies list, you may once again follow the Specifying Python dependencies instructions to update requirements_lock.txt , call pip-compile directly or modify it manually. If you have a custom package you want to use just point to its .whl file directly (remember, work in terms of files, not installations) from your lock (note, requirements.txt and requirements_lock.txt files support local wheel references). If your requirements_lock.txt is already specified as a dependency to python_init_repositories() in WORKSPACE file you don’t have to do anything else. Otherwise you can point to your custom file as follows: \n",
      "```python\n",
      "--repo_env=HERMETIC_REQUIREMENTS_LOCK=\"/absolute/path/to/custom_requirements_lock.txt\"\n",
      "```\n",
      " Also note if you use HERMETIC_REQUIREMENTS_LOCK then it fully controls list of your dependencies and the automatic local wheels resolution logic described in Specifying dependencies on local wheels gets disabled to not interfere with it. That is it. To summarize: if you have an archive with Python interpreter in it and a requirements_lock.txt file with full transitive closure of your dependencies then you fully control your Python environment. Custom hermetic Python examples # Note, for all of the examples below you may also set the environment variables globally (i.e. export in your shell instead of --repo_env argument to your command) so calling bazel via build/build.py will work just fine. Build with custom Python 3.13 from the internet, using default requirements_lock_3_13.txt already checked in this repo (i.e. custom interpreter but default dependencies): \n",
      "```python\n",
      "bazel build <target>\n",
      "  --repo_env=HERMETIC_PYTHON_VERSION=3.13\n",
      "  --repo_env=HERMETIC_PYTHON_URL=\"https://github.com/indygreg/python-build-standalone/releases/download/20241016/cpython-3.13.0+20241016-x86_64-unknown-linux-gnu-install_only.tar.gz\"\n",
      "  --repo_env=HERMETIC_PYTHON_SHA256=\"2c8cb15c6a2caadaa98af51df6fe78a8155b8471cb3dd7b9836038e0d3657fb4\"\n",
      "```\n",
      " Build with custom Python 3.13 from local file system and custom lock file (assuming the lock file was put in jax/build folder of this repo before running the command): \n",
      "```python\n",
      "bazel test <target>\n",
      "  --repo_env=HERMETIC_PYTHON_VERSION=3.13\n",
      "  --repo_env=HERMETIC_PYTHON_URL=\"file:///path/to/cpython.tar.gz\"\n",
      "  --repo_env=HERMETIC_PYTHON_PREFIX=\"prefix/to/strip/in/cython/tar/gz/archive\"\n",
      "  --repo_env=HERMETIC_PYTHON_SHA256=<sha256_sum>\n",
      "  --repo_env=HERMETIC_REQUIREMENTS_LOCK=\"/absolute/path/to/build:custom_requirements_lock.txt\"\n",
      "```\n",
      " If default python interpreter is good enough for you and you just need a custom set of dependencies: \n",
      "```python\n",
      "bazel test <target>\n",
      "  --repo_env=HERMETIC_PYTHON_VERSION=3.13\n",
      "  --repo_env=HERMETIC_REQUIREMENTS_LOCK=\"/absolute/path/to/build:custom_requirements_lock.txt\"\n",
      "```\n",
      " Note, you can have multiple different requirement_lock.txt files corresponding to the same Python version to support different scenarios. You can control which one is selected by specifying HERMETIC_PYTHON_VERSION . For example in WORKSPACE file: \n",
      "```python\n",
      "requirements = {\n",
      "  \"3.10\": \"//build:requirements_lock_3_10.txt\",\n",
      "  \"3.11\": \"//build:requirements_lock_3_11.txt\",\n",
      "  \"3.12\": \"//build:requirements_lock_3_12.txt\",\n",
      "  \"3.13\": \"//build:requirements_lock_3_13.txt\",\n",
      "  \"3.13-scenario1\": \"//build:scenario1_requirements_lock_3_13.txt\",\n",
      "  \"3.13-scenario2\": \"//build:scenario2_requirements_lock_3_13.txt\",\n",
      "},\n",
      "```\n",
      " Then you can build and test different combinations of stuff without changing anything in your environment: \n",
      "```python\n",
      "# To build with scenario1 dependendencies:\n",
      "bazel test <target> --repo_env=HERMETIC_PYTHON_VERSION=3.13-scenario1\n",
      "\n",
      "# To build with scenario2 dependendencies:\n",
      "bazel test <target> --repo_env=HERMETIC_PYTHON_VERSION=3.13-scenario2\n",
      "\n",
      "# To build with default dependendencies:\n",
      "bazel test <target> --repo_env=HERMETIC_PYTHON_VERSION=3.13\n",
      "\n",
      "# To build with scenario1 dependendencies and custom Python 3.13 interpreter:\n",
      "bazel test <target>\n",
      "  --repo_env=HERMETIC_PYTHON_VERSION=3.13-scenario1\n",
      "  --repo_env=HERMETIC_PYTHON_URL=\"file:///path/to/cpython.tar.gz\"\n",
      "  --repo_env=HERMETIC_PYTHON_SHA256=<sha256_sum>\n",
      "```\n",
      " Installing jax # Once jaxlib has been installed, you can install jax by running: pip install - e . # installs jax To upgrade to the latest version from GitHub, just run git pull from the JAX repository root, and rebuild by running build.py or upgrading jaxlib if necessary. You shouldn’t have to reinstall jax because pip install -e sets up symbolic links from site-packages into the repository. Running the tests # There are two supported mechanisms for running the JAX tests, either using Bazel or using pytest. Using Bazel # First, configure the JAX build by using the --configure_only flag. Pass --wheel_list=jaxlib for CPU tests and CUDA/ROCM for GPU for GPU tests: \n",
      "```python\n",
      "python build/build.py build --wheels=jaxlib --configure_only\n",
      "python build/build.py build --wheels=jax-cuda-plugin --configure_only\n",
      "python build/build.py build --wheels=jax-rocm-plugin --configure_only\n",
      "```\n",
      " You may pass additional options to build.py to configure the build; see the jaxlib build documentation for details. By default the Bazel build runs the JAX tests using jaxlib built from source. To run JAX tests, run: \n",
      "```python\n",
      "bazel test //tests:cpu_tests //tests:backend_independent_tests\n",
      "```\n",
      " //tests:gpu_tests and //tests:tpu_tests are also available, if you have the necessary hardware. To use the preinstalled jax and jaxlib instead of building them you first need to make them available in the hermetic Python. To install the specific versions of jax and jaxlib within hermetic Python run (using jax >= 0.4.26 and jaxlib >= 0.4.26 as an example): \n",
      "```python\n",
      "echo -e \"\\njax >= 0.4.26\" >> build/requirements.in\n",
      "echo -e \"\\njaxlib >= 0.4.26\" >> build/requirements.in\n",
      "python build/build.py requirements_update\n",
      "```\n",
      " Alternatively, to install jax and jaxlib from the local wheels (assuming Python 3.12): \n",
      "```python\n",
      "echo -e \"\\n$(realpath jax-0.4.26-py3-none-any.whl)\" >> build/requirements.in\n",
      "echo -e \"\\n$(realpath jaxlib-0.4.26-cp312-cp312-manylinux2014_x86_64.whl)\" >> build/requirements.in\n",
      "python build/build.py requirements_update --python_version=3.12\n",
      "```\n",
      " Once you have jax and jaxlib installed hermetically, run: \n",
      "```python\n",
      "bazel test --//jax:build_jaxlib=false //tests:cpu_tests //tests:backend_independent_tests\n",
      "```\n",
      " A number of test behaviors can be controlled using environment variables (see below). Environment variables may be passed to JAX tests using the --test_env=FLAG=value flag to Bazel. Some of JAX tests are for multiple accelerators (i.e. GPUs, TPUs). When JAX is already installed, you can run GPUs tests like this: \n",
      "```python\n",
      "bazel test //tests:gpu_tests --local_test_jobs=4 --test_tag_filters=multiaccelerator --//jax:build_jaxlib=false --test_env=XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
      "```\n",
      " You can speed up single accelerator tests by running them in parallel on multiple accelerators. This also triggers multiple concurrent tests per accelerator. For GPUs, you can do it like this: \n",
      "```python\n",
      "NB_GPUS=2\n",
      "JOBS_PER_ACC=4\n",
      "J=$((NB_GPUS * JOBS_PER_ACC))\n",
      "MULTI_GPU=\"--run_under $PWD/build/parallel_accelerator_execute.sh --test_env=JAX_ACCELERATOR_COUNT=${NB_GPUS} --test_env=JAX_TESTS_PER_ACCELERATOR=${JOBS_PER_ACC} --local_test_jobs=$J\"\n",
      "bazel test //tests:gpu_tests //tests:backend_independent_tests --test_env=XLA_PYTHON_CLIENT_PREALLOCATE=false --test_tag_filters=-multiaccelerator $MULTI_GPU\n",
      "```\n",
      " Using pytest # First, install the dependencies by running pip install -r build/test-requirements.txt . To run all the JAX tests using pytest , we recommend using pytest-xdist , which can run tests in parallel. It is installed as a part of pip install -r build/test-requirements.txt command. From the repository root directory run: pytest - n auto tests Controlling test behavior # JAX generates test cases combinatorially, and you can control the number of cases that are generated and checked for each test (default is 10) using the JAX_NUM_GENERATED_CASES environment variable. The automated tests currently use 25 by default. For example, one might write \n",
      "```python\n",
      "# Bazel\n",
      "bazel test //tests/... --test_env=JAX_NUM_GENERATED_CASES=25`\n",
      "```\n",
      " or \n",
      "```python\n",
      "# pytest\n",
      "JAX_NUM_GENERATED_CASES=25 pytest -n auto tests\n",
      "```\n",
      " The automated tests also run the tests with default 64-bit floats and ints ( JAX_ENABLE_X64 ): \n",
      "```python\n",
      "JAX_ENABLE_X64=1 JAX_NUM_GENERATED_CASES=25 pytest -n auto tests\n",
      "```\n",
      " You can run a more specific set of tests using pytest ’s built-in selection mechanisms, or alternatively you can run a specific test file directly to see more detailed information about the cases being run: \n",
      "```python\n",
      "JAX_NUM_GENERATED_CASES=5 python tests/lax_numpy_test.py\n",
      "```\n",
      " You can skip a few tests known to be slow, by passing environment variable JAX_SKIP_SLOW_TESTS=1. To specify a particular set of tests to run from a test file, you can pass a string or regular expression via the --test_targets flag. For example, you can run all the tests of jax.numpy.pad using: \n",
      "```python\n",
      "python tests/lax_numpy_test.py --test_targets=\"testPad\"\n",
      "```\n",
      " The Colab notebooks are tested for errors as part of the documentation build. Hypothesis tests # Some of the tests use hypothesis . Normally, hypothesis will test using multiple example inputs, and on a test failure it will try to find a smaller example that still results in failure: Look through the test failure for a line like the one below, and add the decorator mentioned in the message: \n",
      "```python\n",
      "You can reproduce this example by temporarily adding @reproduce_failure('6.97.4', b'AXicY2DAAAAAEwAB') as a decorator on your test case\n",
      "```\n",
      " For interactive development, you can set the environment variable JAX_HYPOTHESIS_PROFILE=interactive (or the equivalent flag --jax_hypothesis_profile=interactive ) in order to set the number of examples to 1, and skip the example minimization phase. Doctests # JAX uses pytest in doctest mode to test the code examples within the documentation. You can find the up-to-date command to run doctests in ci-build.yaml . E.g., you can run: \n",
      "```python\n",
      "JAX_TRACEBACK_FILTERING=off XLA_FLAGS=--xla_force_host_platform_device_count=8 pytest -n auto --tb=short --doctest-glob='*.md' --doctest-glob='*.rst' docs --doctest-continue-on-failure --ignore=docs/multi_process.md\n",
      "```\n",
      " Additionally, JAX runs pytest in doctest-modules mode to ensure code examples in function docstrings will run correctly. You can run this locally using, for example: \n",
      "```python\n",
      "JAX_TRACEBACK_FILTERING=off XLA_FLAGS=--xla_force_host_platform_device_count=8 pytest --doctest-modules jax/_src/numpy/lax_numpy.py\n",
      "```\n",
      " Type checking # We use mypy to check the type hints. To run mypy with the same configuration as the github CI checks, you can use the pre-commit framework: \n",
      "```python\n",
      "pip install pre-commit\n",
      "pre-commit run mypy --all-files\n",
      "```\n",
      " Because mypy can be somewhat slow when checking all files, it may be convenient to only check files you have modified. To do this, first stage the changes (i.e. git add the changed files) and then run this before committing the changes: pre - commit run mypy Linting # JAX uses the ruff linter to ensure code quality. To run ruff with the same configuration as the github CI checks, you can use the pre-commit framework: \n",
      "```python\n",
      "pip install pre-commit\n",
      "pre-commit run ruff --all-files\n",
      "```\n",
      " Update documentation # To rebuild the documentation, install several packages: pip install - r docs / requirements . txt And then run: sphinx - build - b html docs docs / build / html - j auto This can take a long time because it executes many of the notebooks in the documentation source; if you’d prefer to build the docs without executing the notebooks, you can run: \n",
      "```python\n",
      "sphinx-build -b html -D nb_execution_mode=off docs docs/build/html -j auto\n",
      "```\n",
      " You can then see the generated documentation in docs/build/html/index.html . The -j auto option controls the parallelism of the build. You can use a number in place of auto to control how many CPU cores to use. Update notebooks # We use jupytext to maintain two synced copies of the notebooks in docs/notebooks : one in ipynb format, and one in md format. The advantage of the former is that it can be opened and executed directly in Colab; the advantage of the latter is that it makes it much easier to track diffs within version control. Editing ipynb # For making large changes that substantially modify code and outputs, it is easiest to edit the notebooks in Jupyter or in Colab. To edit notebooks in the Colab interface, open http://colab.research.google.com and Upload from your local repo. Update it as needed, Run all cells then Download ipynb . You may want to test that it executes properly, using sphinx-build as explained above. Editing md # For making smaller changes to the text content of the notebooks, it is easiest to edit the .md versions using a text editor. Syncing notebooks # After editing either the ipynb or md versions of the notebooks, you can sync the two versions using jupytext by running jupytext --sync on the updated notebooks; for example: \n",
      "```python\n",
      "pip install jupytext==1.16.4\n",
      "jupytext --sync docs/notebooks/thinking_in_jax.ipynb\n",
      "```\n",
      " The jupytext version should match that specified in .pre-commit-config.yaml . To check that the markdown and ipynb files are properly synced, you may use the pre-commit framework to perform the same check used by the github CI: \n",
      "```python\n",
      "pip install pre-commit\n",
      "pre-commit run jupytext --all-files\n",
      "```\n",
      " Creating new notebooks # If you are adding a new notebook to the documentation and would like to use the jupytext --sync command discussed here, you can set up your notebook for jupytext by using the following command: \n",
      "```python\n",
      "jupytext --set-formats ipynb,md:myst path/to/the/notebook.ipynb\n",
      "```\n",
      " This works by adding a \"jupytext\" metadata field to the notebook file which specifies the desired formats, and which the jupytext --sync command recognizes when invoked. Notebooks within the Sphinx build # Some of the notebooks are built automatically as part of the pre-submit checks and as part of the Read the docs build. The build will fail if cells raise errors. If the errors are intentional, you can either catch them, or tag the cell with raises-exceptions metadata ( example PR ). You have to add this metadata by hand in the .ipynb file. It will be preserved when somebody else re-saves the notebook. We exclude some notebooks from the build, e.g., because they contain long computations. See exclude_patterns in conf.py . Documentation building on readthedocs.io # JAX’s auto-generated documentation is at https://jax.readthedocs.io/ . The documentation building is controlled for the entire project by the readthedocs JAX settings . The current settings trigger a documentation build as soon as code is pushed to the GitHub main branch. For each code version, the building process is driven by the .readthedocs.yml and the docs/conf.py configuration files. For each automated documentation build you can see the documentation build logs . If you want to test the documentation generation on Readthedocs, you can push code to the test-docs branch. That branch is also built automatically, and you can see the generated documentation here . If the documentation build fails you may want to wipe the build environment for test-docs . For a local test, I was able to do it in a fresh directory by replaying the commands I saw in the Readthedocs logs: \n",
      "```python\n",
      "mkvirtualenv jax-docs  # A new virtualenv\n",
      "mkdir jax-docs  # A new directory\n",
      "cd jax-docs\n",
      "git clone --no-single-branch --depth 50 https://github.com/jax-ml/jax\n",
      "cd jax\n",
      "git checkout --force origin/test-docs\n",
      "git clean -d -f -f\n",
      "workon jax-docs\n",
      "\n",
      "python -m pip install --upgrade --no-cache-dir pip\n",
      "python -m pip install --upgrade --no-cache-dir -I Pygments==2.3.1 setuptools==41.0.1 docutils==0.14 mock==1.0.1 pillow==5.4.1 alabaster>=0.7,<0.8,!=0.7.5 commonmark==0.8.1 recommonmark==0.5.0 'sphinx<2' 'sphinx-rtd-theme<0.5' 'readthedocs-sphinx-ext<1.1'\n",
      "python -m pip install --exists-action=w --no-cache-dir -r docs/requirements.txt\n",
      "cd docs\n",
      "python `which sphinx-build` -T -E -b html -d _build/doctrees-readthedocs -D language=en . _build/html\n",
      "```\n",
      "...\n",
      "Code blocks: 45\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load your preprocessed data\n",
    "with open('processed_jax_docs/jax_knowledge_base.json', 'r') as f:\n",
    "    knowledge_base = json.load(f)\n",
    "\n",
    "# Check a sample entry\n",
    "sample_doc = knowledge_base[0]\n",
    "print(f\"Title: {sample_doc['title']}\")\n",
    "print(f\"Content snippet: {sample_doc['content']}...\")\n",
    "print(f\"Code blocks: {len(sample_doc['code_blocks'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone in /usr/local/python/3.12.1/lib/python3.12/site-packages (6.0.2)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.22-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /home/codespace/.local/lib/python3.12/site-packages (from pinecone) (2025.1.31)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/codespace/.local/lib/python3.12/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/codespace/.local/lib/python3.12/site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /home/codespace/.local/lib/python3.12/site-packages (from pinecone) (2.3.0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.49 (from langchain)\n",
      "  Downloading langchain_core-0.3.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.22-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langchain) (2.11.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langchain_community) (3.11.16)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.49->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.22-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.3.49-py3-none-any.whl (420 kB)\n",
      "Downloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.22-py3-none-any.whl (352 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading orjson-3.10.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: zstandard, tenacity, SQLAlchemy, orjson, mypy-extensions, marshmallow, jsonpatch, httpx-sse, typing-inspect, requests-toolbelt, pydantic-settings, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.40 dataclasses-json-0.6.7 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.22 langchain-core-0.3.49 langchain-text-splitters-0.3.7 langchain_community-0.3.20 langsmith-0.3.22 marshmallow-3.26.1 mypy-extensions-1.0.0 orjson-3.10.16 pydantic-settings-2.8.1 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspect-0.9.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (2.6.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-4.0.1-py3-none-any.whl (340 kB)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Installing collected packages: safetensors, transformers, sentence-transformers\n",
      "Successfully installed safetensors-0.5.3 sentence-transformers-4.0.1 transformers-4.50.3\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "class JAXFAISSRetriever:\n",
    "    def __init__(self, knowledge_base_path: str):\n",
    "        # Initialize embeddings\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  \n",
    "        \n",
    "        # Load knowledge base\n",
    "        self.knowledge_base = self._load_knowledge_base(knowledge_base_path)\n",
    "        \n",
    "        # Initialize vector stores\n",
    "        self.vectorstore, self.docstore = self._create_vector_stores()\n",
    "        \n",
    "        # Create retriever\n",
    "        self.retriever = MultiVectorRetriever(\n",
    "            vectorstore=self.vectorstore,\n",
    "            docstore=self.docstore,\n",
    "            id_key=\"doc_id\"\n",
    "        )\n",
    "    \n",
    "    def _load_knowledge_base(self, path: str) -> List[Dict]:\n",
    "        \"\"\"Load preprocessed knowledge base from JSON file\"\"\"\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def _create_vector_stores(self):\n",
    "        \"\"\"Create FAISS vector store and document store\"\"\"\n",
    "        # Prepare documents\n",
    "        documents = []\n",
    "        metadatas = []\n",
    "        ids = []\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        \n",
    "        for doc in self.knowledge_base:\n",
    "            # Split document content\n",
    "            splits = text_splitter.split_text(doc['content'])\n",
    "            for i, split in enumerate(splits):\n",
    "                doc_id = f\"{doc['id']}_{i}\"\n",
    "                documents.append(split)\n",
    "                metadatas.append({\n",
    "                    'type': 'documentation',\n",
    "                    'title': doc['title'],\n",
    "                    'source': doc['path'],\n",
    "                    'doc_id': doc['id'],\n",
    "                    'chunk_id': i\n",
    "                })\n",
    "                ids.append(doc_id)\n",
    "            \n",
    "            # Add code blocks\n",
    "            for i, code_block in enumerate(doc['code_blocks']):\n",
    "                code_id = f\"code_{doc['id']}_{i}\"\n",
    "                documents.append(code_block)\n",
    "                metadatas.append({\n",
    "                    'type': 'code',\n",
    "                    'title': doc['title'],\n",
    "                    'source': doc['path'],\n",
    "                    'doc_id': doc['id'],\n",
    "                    'code_block_id': i\n",
    "                })\n",
    "                ids.append(code_id)\n",
    "        \n",
    "        # Create FAISS vector store\n",
    "        vectorstore = FAISS.from_texts(\n",
    "            texts=documents,\n",
    "            embedding=self.embeddings,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        \n",
    "        # Create document store - CORRECTED IMPLEMENTATION\n",
    "        docstore = InMemoryStore()\n",
    "        # Convert to list of tuples as required by mset\n",
    "        docstore.mset([(doc['id'], doc) for doc in self.knowledge_base])\n",
    "        \n",
    "        return vectorstore, docstore\n",
    "    \n",
    "    def query(self, question: str, include_code: bool = True, top_k: int = 3):\n",
    "        \"\"\"Execute a query with optional code filtering\"\"\"\n",
    "        if include_code:\n",
    "            docs = self.vectorstore.similarity_search(\n",
    "                question,\n",
    "                k=top_k,\n",
    "                filter=lambda meta: meta.get('type') == 'code'\n",
    "            )\n",
    "        else:\n",
    "            docs = self.vectorstore.similarity_search(\n",
    "                question,\n",
    "                k=top_k,\n",
    "                filter=lambda meta: meta.get('type') == 'documentation'\n",
    "            )\n",
    "        \n",
    "        # Convert to LangChain Document objects\n",
    "        lc_docs = [\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            ) for doc in docs\n",
    "        ]\n",
    "        \n",
    "        # Get full documents for context\n",
    "        doc_ids = list(set([doc.metadata['doc_id'] for doc in docs]))\n",
    "        full_docs = [doc for doc in self.docstore.mget(doc_ids) if doc is not None]\n",
    "        \n",
    "        return {\n",
    "            \"relevant_chunks\": lc_docs,\n",
    "            \"source_documents\": full_docs\n",
    "        }\n",
    "    \n",
    "    def save_index(self, path: str):\n",
    "        \"\"\"Save FAISS index to disk\"\"\"\n",
    "        self.vectorstore.save_local(path)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_index(cls, path: str, knowledge_base_path: str):\n",
    "        \"\"\"Load FAISS index from disk\"\"\"\n",
    "        retriever = cls(knowledge_base_path)\n",
    "        retriever.vectorstore = FAISS.load_local(\n",
    "            path,\n",
    "            retriever.embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "From Distributed arrays and automatic parallelization — JAX  documentation (code):\n",
      "import jax\n",
      "import jax.numpy as jnp...\n",
      "\n",
      "From Control autodiff’s saved values with jax.checkpoint (aka jax.remat) — JAX  documentation (code):\n",
      "import jax\n",
      "import jax.numpy as jnp...\n",
      "\n",
      "From jax.named_scope — JAX  documentation (code):\n",
      ">>> import jax\n",
      ">>>\n",
      ">>> @jax.jit\n",
      "... def layer(w, x):\n",
      "...   with jax.named_scope(\"dot_product\"):\n",
      "...     logits = w.dot(x)\n",
      "...   with jax.named_scope(\"activation\"):\n",
      "...     return jax.nn.relu(logits)...\n"
     ]
    }
   ],
   "source": [
    "# Initialize retriever\n",
    "retriever = JAXFAISSRetriever('processed_jax_docs/jax_knowledge_base.json')\n",
    "\n",
    "# Save index for later use\n",
    "retriever.save_index(\"jax_faiss_index\")\n",
    "\n",
    "# Query examples\n",
    "results = retriever.query(\n",
    "    \"How to use jax.jit with a neural network?\",\n",
    "    include_code=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for chunk in results[\"relevant_chunks\"]:\n",
    "    print(f\"\\nFrom {chunk.metadata['title']} ({chunk.metadata['type']}):\")\n",
    "    print(chunk.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "From External callbacks — JAX  documentation (code):\n",
      "x = jnp.arange(5.0)\n",
      "jax.vmap(f)(x);...\n",
      "\n",
      "From Introduction to debugging — JAX  documentation (code):\n",
      "x = jnp.arange(5.0)\n",
      "jax.vmap(f)(x);...\n",
      "\n",
      "From Pseudorandom numbers — JAX  documentation (code):\n",
      "import jax\n",
      "print(\"vectorized:\", jax.vmap(random.normal)(subkeys))...\n"
     ]
    }
   ],
   "source": [
    "results = retriever.query(\n",
    "    \"How to use jax.vmap with multiple arguments?\",\n",
    "    include_code=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for chunk in results[\"relevant_chunks\"]:\n",
    "    print(f\"\\nFrom {chunk.metadata['title']} ({chunk.metadata['type']}):\")\n",
    "    print(chunk.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "[Explanation]\n",
      "The `jax.vmap` function in JAX is used to vectorize or batch computations over one or more arguments of a function. It is a powerful tool for parallelizing computations over a batch dimension. \n",
      "\n",
      "When using `jax.vmap` with multiple arguments, you need to specify the `in_axes` parameter to indicate which axes of the input arguments should be mapped over. The `in_axes` parameter can be a tuple, list, or dictionary, depending on the structure of the input arguments. \n",
      "\n",
      "If the function you want to vectorize takes multiple arguments, you can pass them as a tuple to `jax.vmap`. The `in_axes` parameter should also be a tuple of the same length, specifying the axis to map for each argument. If an argument should not be mapped over, you can specify its axis as `None`.\n",
      "\n",
      "[Code Example]\n",
      "```python\n",
      "import jax\n",
      "import jax.numpy as jnp\n",
      "\n",
      "# Define a function that takes two arguments\n",
      "def f(x, y):\n",
      "  return x + y\n",
      "\n",
      "# Create some data\n",
      "x = jnp.arange(5.0)\n",
      "y = jnp.arange(5.0, 10.0)\n",
      "\n",
      "# Use vmap to vectorize the function over the 0th axis of both arguments\n",
      "f_vectorized = jax.vmap(f, in_axes=(0, 0))\n",
      "\n",
      "# Call the vectorized function\n",
      "result = f_vectorized(x, y)\n",
      "\n",
      "print(result)  # prints: [ 5.  7.  9. 11. 13.]\n",
      "```\n",
      "\n",
      "[Additional Notes]\n",
      "The `in_axes` parameter can also be a dictionary if the function takes keyword arguments. For example, if the function is defined as `f(a, b, c=None)`, you can use `in_axes=(0, 0, None)` to map over the first two arguments and not map over the third one. \n",
      "\n",
      "Also, note that the `jax.vmap` function returns a new function that you can call with batched inputs. The original function `f` is not modified.\n",
      "\n",
      "Sources:\n",
      "- Building on JAX — JAX  documentation (chunk 2)\n",
      "- Working with pytrees — JAX  documentation (chunk 20)\n",
      "- jax.custom_batching.custom_vmap — JAX  documentation (chunk 0)\n",
      "- External callbacks — JAX  documentation (chunk code)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Create a comprehensive prompt template that encourages code examples\n",
    "prompt_template = \"\"\"You are an expert in JAX and machine learning. Use the following pieces of context to answer the question at the end. \n",
    "If the question involves code or implementation details, always provide a complete, executable code example using JAX.\n",
    "\n",
    "Context information:\n",
    "-------------------\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "When providing code examples:\n",
    "1. Use proper JAX imports (jax.numpy as jnp, jax, etc.)\n",
    "2. Include type annotations where appropriate\n",
    "3. Add brief comments explaining key parts\n",
    "4. Ensure the code is syntactically correct\n",
    "\n",
    "Answer in the following format:\n",
    "[Explanation] Provide a clear explanation of the concept or solution\n",
    "[Code Example] (if applicable):\n",
    "```python\n",
    "# Your code here\n",
    "[Additional Notes] Any caveats or important considerations\"\"\"\n",
    "\n",
    "QA_PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever.vectorstore.as_retriever(),  \n",
    "    chain_type_kwargs={\"prompt\": QA_PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "\n",
    "question = \"How to use jax.vmap with multiple arguments?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(result[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- {doc.metadata['title']} (chunk {doc.metadata.get('chunk_id', 'code')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "[Explanation]\n",
      "JAX's `grad` function is used for automatic differentiation. It takes a function as an input and returns a new function that computes the gradient of the input function. The gradient of a function at a certain point is a vector that points in the direction of the greatest rate of increase of the function at that point, and its magnitude is the rate of increase in that direction.\n",
      "\n",
      "In the context of machine learning, gradients are used to update the parameters of models during training in order to minimize a loss function. The `grad` function in JAX makes it easy to compute these gradients.\n",
      "\n",
      "One of the powerful features of JAX's `grad` function is that it can be applied to its own output to compute higher-order derivatives. This is because the functions that compute derivatives are themselves differentiable in JAX.\n",
      "\n",
      "[Code Example]\n",
      "```python\n",
      "import jax\n",
      "import jax.numpy as jnp\n",
      "from jax import grad\n",
      "\n",
      "# Define a function\n",
      "f = lambda x: x**3 + 2*x**2 - 3*x + 1\n",
      "\n",
      "# Compute the gradient of the function\n",
      "grad_f = grad(f)\n",
      "\n",
      "# Evaluate the gradient at a point\n",
      "print(grad_f(2.0))  # Output: 11.0\n",
      "\n",
      "# Compute the second-order derivative\n",
      "grad2_f = grad(grad(f))\n",
      "\n",
      "# Evaluate the second-order derivative at a point\n",
      "print(grad2_f(2.0))  # Output: 14.0\n",
      "```\n",
      "\n",
      "[Additional Notes]\n",
      "It's important to note that JAX's `grad` function can only be used to compute the gradients of scalar-valued functions with respect to their parameters. If you need to compute the gradient of a function that returns a vector, you can use the `vmap` function in JAX to vectorize the gradient computation.\n"
     ]
    }
   ],
   "source": [
    "question = \"How does JAX's grad function work for automatic differentiation?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.44.1)\n",
      "Collecting streamlit_chat\n",
      "  Downloading streamlit_chat-0.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /home/codespace/.local/lib/python3.12/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/codespace/.local/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /home/codespace/.local/lib/python3.12/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /home/codespace/.local/lib/python3.12/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/codespace/.local/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /home/codespace/.local/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit_chat-0.1.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: streamlit_chat\n",
      "Successfully installed streamlit_chat-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit streamlit_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting temp_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile temp_app.py\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set Streamlit page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"JAX Helper Bot\",\n",
    "    page_icon=\"🦜\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Initialize retriever\n",
    "knowledge_base_path = \"jax_faiss_index/index.faiss\"  # Change path if needed\n",
    "retriever = JAXFAISSRetriever(knowledge_base_path)\n",
    "\n",
    "# Function to create source links\n",
    "def create_sources_string(sources):\n",
    "    if not sources:\n",
    "        return \"\"\n",
    "    sources_string = \"Sources:\\n\"\n",
    "    for i, source in enumerate(sorted(sources)):\n",
    "        sources_string += f\"{i+1}. {source}\\n\"\n",
    "    return sources_string\n",
    "\n",
    "# Sidebar\n",
    "with st.sidebar:\n",
    "    st.title(\"User Profile\")\n",
    "    user_name = \"Manish Sharma\"\n",
    "    user_email = \"manishsharma@gmail.com\"\n",
    "    st.write(f\"**Name:** {user_name}\")\n",
    "    st.write(f\"**Email:** {user_email}\")\n",
    "\n",
    "st.header(\"JAX Helper Bot 🦜🔗\")\n",
    "\n",
    "# Initialize session state\n",
    "if \"chat_answers_history\" not in st.session_state:\n",
    "    st.session_state[\"chat_answers_history\"] = []\n",
    "    st.session_state[\"user_prompt_history\"] = []\n",
    "\n",
    "# User input\n",
    "prompt = st.text_input(\"Ask a question about JAX:\", placeholder=\"How to use jax.vmap with multiple arguments?\")\n",
    "\n",
    "if st.button(\"Submit\") and prompt:\n",
    "    with st.spinner(\"Fetching relevant documents and generating response...\"):\n",
    "        retrieval_result = retriever.query(prompt)\n",
    "        qa_result = qa_chain({\"query\": prompt, \"context\": retrieval_result[\"relevant_chunks\"]})\n",
    "        \n",
    "        sources = set(doc.metadata[\"source\"] for doc in retrieval_result[\"source_documents\"])\n",
    "        formatted_response = f\"{qa_result['result']}\\n\\n{create_sources_string(sources)}\"\n",
    "        \n",
    "        # Store chat history\n",
    "        st.session_state[\"user_prompt_history\"].append(prompt)\n",
    "        st.session_state[\"chat_answers_history\"].append(formatted_response)\n",
    "\n",
    "# Display chat history\n",
    "if st.session_state[\"chat_answers_history\"]:\n",
    "    for user_query, response in zip(st.session_state[\"user_prompt_history\"], st.session_state[\"chat_answers_history\"]):\n",
    "        message(user_query, is_user=True, key=f\"user_{user_query}\")\n",
    "        message(response, key=f\"bot_{response}\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"Powered by LangChain and Streamlit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
